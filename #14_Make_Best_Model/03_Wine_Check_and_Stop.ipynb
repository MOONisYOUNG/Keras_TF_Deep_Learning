{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105a997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dcc5a2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.15465, saving model to ./code_03_model_result\\01-1.1546.hdf5\n",
      "\n",
      "Epoch 2: val_loss improved from 1.15465 to 0.87845, saving model to ./code_03_model_result\\02-0.8785.hdf5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.87845 to 0.66765, saving model to ./code_03_model_result\\03-0.6676.hdf5\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.66765\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.66765\n",
      "\n",
      "Epoch 6: val_loss improved from 0.66765 to 0.58536, saving model to ./code_03_model_result\\06-0.5854.hdf5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.58536 to 0.54633, saving model to ./code_03_model_result\\07-0.5463.hdf5\n",
      "\n",
      "Epoch 8: val_loss improved from 0.54633 to 0.52217, saving model to ./code_03_model_result\\08-0.5222.hdf5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.52217 to 0.48623, saving model to ./code_03_model_result\\09-0.4862.hdf5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.48623 to 0.45511, saving model to ./code_03_model_result\\10-0.4551.hdf5\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.45511\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.45511\n",
      "\n",
      "Epoch 13: val_loss improved from 0.45511 to 0.43349, saving model to ./code_03_model_result\\13-0.4335.hdf5\n",
      "\n",
      "Epoch 14: val_loss improved from 0.43349 to 0.38069, saving model to ./code_03_model_result\\14-0.3807.hdf5\n",
      "\n",
      "Epoch 15: val_loss improved from 0.38069 to 0.35193, saving model to ./code_03_model_result\\15-0.3519.hdf5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.35193 to 0.33609, saving model to ./code_03_model_result\\16-0.3361.hdf5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.33609 to 0.32587, saving model to ./code_03_model_result\\17-0.3259.hdf5\n",
      "\n",
      "Epoch 18: val_loss improved from 0.32587 to 0.32447, saving model to ./code_03_model_result\\18-0.3245.hdf5\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.32447\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.32447\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.32447\n",
      "\n",
      "Epoch 22: val_loss improved from 0.32447 to 0.30639, saving model to ./code_03_model_result\\22-0.3064.hdf5\n",
      "\n",
      "Epoch 23: val_loss improved from 0.30639 to 0.28939, saving model to ./code_03_model_result\\23-0.2894.hdf5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.28939 to 0.27850, saving model to ./code_03_model_result\\24-0.2785.hdf5\n",
      "\n",
      "Epoch 25: val_loss improved from 0.27850 to 0.27270, saving model to ./code_03_model_result\\25-0.2727.hdf5\n",
      "\n",
      "Epoch 26: val_loss improved from 0.27270 to 0.27060, saving model to ./code_03_model_result\\26-0.2706.hdf5\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.27060\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.27060\n",
      "\n",
      "Epoch 29: val_loss improved from 0.27060 to 0.26784, saving model to ./code_03_model_result\\29-0.2678.hdf5\n",
      "\n",
      "Epoch 30: val_loss improved from 0.26784 to 0.25650, saving model to ./code_03_model_result\\30-0.2565.hdf5\n",
      "\n",
      "Epoch 31: val_loss improved from 0.25650 to 0.24669, saving model to ./code_03_model_result\\31-0.2467.hdf5\n",
      "\n",
      "Epoch 32: val_loss improved from 0.24669 to 0.24114, saving model to ./code_03_model_result\\32-0.2411.hdf5\n",
      "\n",
      "Epoch 33: val_loss improved from 0.24114 to 0.23899, saving model to ./code_03_model_result\\33-0.2390.hdf5\n",
      "\n",
      "Epoch 34: val_loss improved from 0.23899 to 0.23790, saving model to ./code_03_model_result\\34-0.2379.hdf5\n",
      "\n",
      "Epoch 35: val_loss improved from 0.23790 to 0.23760, saving model to ./code_03_model_result\\35-0.2376.hdf5\n",
      "\n",
      "Epoch 36: val_loss improved from 0.23760 to 0.23664, saving model to ./code_03_model_result\\36-0.2366.hdf5\n",
      "\n",
      "Epoch 37: val_loss improved from 0.23664 to 0.23169, saving model to ./code_03_model_result\\37-0.2317.hdf5\n",
      "\n",
      "Epoch 38: val_loss improved from 0.23169 to 0.22596, saving model to ./code_03_model_result\\38-0.2260.hdf5\n",
      "\n",
      "Epoch 39: val_loss improved from 0.22596 to 0.22193, saving model to ./code_03_model_result\\39-0.2219.hdf5\n",
      "\n",
      "Epoch 40: val_loss improved from 0.22193 to 0.21839, saving model to ./code_03_model_result\\40-0.2184.hdf5\n",
      "\n",
      "Epoch 41: val_loss improved from 0.21839 to 0.21804, saving model to ./code_03_model_result\\41-0.2180.hdf5\n",
      "\n",
      "Epoch 42: val_loss improved from 0.21804 to 0.21800, saving model to ./code_03_model_result\\42-0.2180.hdf5\n",
      "\n",
      "Epoch 43: val_loss improved from 0.21800 to 0.21726, saving model to ./code_03_model_result\\43-0.2173.hdf5\n",
      "\n",
      "Epoch 44: val_loss improved from 0.21726 to 0.21486, saving model to ./code_03_model_result\\44-0.2149.hdf5\n",
      "\n",
      "Epoch 45: val_loss improved from 0.21486 to 0.21178, saving model to ./code_03_model_result\\45-0.2118.hdf5\n",
      "\n",
      "Epoch 46: val_loss improved from 0.21178 to 0.20934, saving model to ./code_03_model_result\\46-0.2093.hdf5\n",
      "\n",
      "Epoch 47: val_loss improved from 0.20934 to 0.20374, saving model to ./code_03_model_result\\47-0.2037.hdf5\n",
      "\n",
      "Epoch 48: val_loss improved from 0.20374 to 0.19926, saving model to ./code_03_model_result\\48-0.1993.hdf5\n",
      "\n",
      "Epoch 49: val_loss improved from 0.19926 to 0.19320, saving model to ./code_03_model_result\\49-0.1932.hdf5\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.19320\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.19320\n",
      "\n",
      "Epoch 52: val_loss improved from 0.19320 to 0.19252, saving model to ./code_03_model_result\\52-0.1925.hdf5\n",
      "\n",
      "Epoch 53: val_loss improved from 0.19252 to 0.18843, saving model to ./code_03_model_result\\53-0.1884.hdf5\n",
      "\n",
      "Epoch 54: val_loss improved from 0.18843 to 0.18671, saving model to ./code_03_model_result\\54-0.1867.hdf5\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.18671\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.18671\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.18671\n",
      "\n",
      "Epoch 58: val_loss improved from 0.18671 to 0.18570, saving model to ./code_03_model_result\\58-0.1857.hdf5\n",
      "\n",
      "Epoch 59: val_loss improved from 0.18570 to 0.18305, saving model to ./code_03_model_result\\59-0.1831.hdf5\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.18305\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.18305\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.18305\n",
      "\n",
      "Epoch 63: val_loss improved from 0.18305 to 0.18230, saving model to ./code_03_model_result\\63-0.1823.hdf5\n",
      "\n",
      "Epoch 64: val_loss improved from 0.18230 to 0.17761, saving model to ./code_03_model_result\\64-0.1776.hdf5\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.17761\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.17761\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.17761\n",
      "\n",
      "Epoch 68: val_loss improved from 0.17761 to 0.17527, saving model to ./code_03_model_result\\68-0.1753.hdf5\n",
      "\n",
      "Epoch 69: val_loss improved from 0.17527 to 0.17268, saving model to ./code_03_model_result\\69-0.1727.hdf5\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.17268\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.17268\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.17268\n",
      "\n",
      "Epoch 73: val_loss improved from 0.17268 to 0.17017, saving model to ./code_03_model_result\\73-0.1702.hdf5\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.17017\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.17017\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.17017\n",
      "\n",
      "Epoch 77: val_loss improved from 0.17017 to 0.16892, saving model to ./code_03_model_result\\77-0.1689.hdf5\n",
      "\n",
      "Epoch 78: val_loss improved from 0.16892 to 0.16868, saving model to ./code_03_model_result\\78-0.1687.hdf5\n",
      "\n",
      "Epoch 79: val_loss improved from 0.16868 to 0.16839, saving model to ./code_03_model_result\\79-0.1684.hdf5\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.16839\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.16839\n",
      "\n",
      "Epoch 82: val_loss improved from 0.16839 to 0.16736, saving model to ./code_03_model_result\\82-0.1674.hdf5\n",
      "\n",
      "Epoch 83: val_loss improved from 0.16736 to 0.16527, saving model to ./code_03_model_result\\83-0.1653.hdf5\n",
      "\n",
      "Epoch 84: val_loss improved from 0.16527 to 0.16400, saving model to ./code_03_model_result\\84-0.1640.hdf5\n",
      "\n",
      "Epoch 85: val_loss improved from 0.16400 to 0.16384, saving model to ./code_03_model_result\\85-0.1638.hdf5\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.16384\n",
      "\n",
      "Epoch 87: val_loss improved from 0.16384 to 0.16330, saving model to ./code_03_model_result\\87-0.1633.hdf5\n",
      "\n",
      "Epoch 88: val_loss improved from 0.16330 to 0.15802, saving model to ./code_03_model_result\\88-0.1580.hdf5\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.15802\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.15802\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.15802\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.15802\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.15802\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.15802\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.15802\n",
      "\n",
      "Epoch 96: val_loss improved from 0.15802 to 0.15610, saving model to ./code_03_model_result\\96-0.1561.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 97: val_loss did not improve from 0.15610\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.15610\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.15610\n",
      "\n",
      "Epoch 100: val_loss improved from 0.15610 to 0.15415, saving model to ./code_03_model_result\\100-0.1541.hdf5\n",
      "\n",
      "Epoch 101: val_loss improved from 0.15415 to 0.15256, saving model to ./code_03_model_result\\101-0.1526.hdf5\n",
      "\n",
      "Epoch 102: val_loss improved from 0.15256 to 0.15213, saving model to ./code_03_model_result\\102-0.1521.hdf5\n",
      "\n",
      "Epoch 103: val_loss did not improve from 0.15213\n",
      "\n",
      "Epoch 104: val_loss did not improve from 0.15213\n",
      "\n",
      "Epoch 105: val_loss improved from 0.15213 to 0.14905, saving model to ./code_03_model_result\\105-0.1491.hdf5\n",
      "\n",
      "Epoch 106: val_loss did not improve from 0.14905\n",
      "\n",
      "Epoch 107: val_loss did not improve from 0.14905\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.14905\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.14905\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.14905\n",
      "\n",
      "Epoch 111: val_loss did not improve from 0.14905\n",
      "\n",
      "Epoch 112: val_loss did not improve from 0.14905\n",
      "\n",
      "Epoch 113: val_loss improved from 0.14905 to 0.14682, saving model to ./code_03_model_result\\113-0.1468.hdf5\n",
      "\n",
      "Epoch 114: val_loss improved from 0.14682 to 0.14352, saving model to ./code_03_model_result\\114-0.1435.hdf5\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.14352\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.14352\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.14352\n",
      "\n",
      "Epoch 118: val_loss improved from 0.14352 to 0.14297, saving model to ./code_03_model_result\\118-0.1430.hdf5\n",
      "\n",
      "Epoch 119: val_loss did not improve from 0.14297\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.14297\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.14297\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.14297\n",
      "\n",
      "Epoch 123: val_loss did not improve from 0.14297\n",
      "\n",
      "Epoch 124: val_loss did not improve from 0.14297\n",
      "\n",
      "Epoch 125: val_loss did not improve from 0.14297\n",
      "\n",
      "Epoch 126: val_loss improved from 0.14297 to 0.14276, saving model to ./code_03_model_result\\126-0.1428.hdf5\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.14276\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.14276\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.14276\n",
      "\n",
      "Epoch 130: val_loss improved from 0.14276 to 0.14068, saving model to ./code_03_model_result\\130-0.1407.hdf5\n",
      "\n",
      "Epoch 131: val_loss did not improve from 0.14068\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.14068\n",
      "\n",
      "Epoch 133: val_loss improved from 0.14068 to 0.13770, saving model to ./code_03_model_result\\133-0.1377.hdf5\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.13770\n",
      "\n",
      "Epoch 135: val_loss did not improve from 0.13770\n",
      "\n",
      "Epoch 136: val_loss did not improve from 0.13770\n",
      "\n",
      "Epoch 137: val_loss did not improve from 0.13770\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.13770\n",
      "\n",
      "Epoch 139: val_loss did not improve from 0.13770\n",
      "\n",
      "Epoch 140: val_loss improved from 0.13770 to 0.13591, saving model to ./code_03_model_result\\140-0.1359.hdf5\n",
      "\n",
      "Epoch 141: val_loss improved from 0.13591 to 0.13503, saving model to ./code_03_model_result\\141-0.1350.hdf5\n",
      "\n",
      "Epoch 142: val_loss did not improve from 0.13503\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.13503\n",
      "\n",
      "Epoch 144: val_loss did not improve from 0.13503\n",
      "\n",
      "Epoch 145: val_loss did not improve from 0.13503\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.13503\n",
      "\n",
      "Epoch 147: val_loss did not improve from 0.13503\n",
      "\n",
      "Epoch 148: val_loss did not improve from 0.13503\n",
      "\n",
      "Epoch 149: val_loss did not improve from 0.13503\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.13503\n",
      "\n",
      "Epoch 151: val_loss did not improve from 0.13503\n",
      "\n",
      "Epoch 152: val_loss improved from 0.13503 to 0.12921, saving model to ./code_03_model_result\\152-0.1292.hdf5\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.12921\n",
      "\n",
      "Epoch 154: val_loss did not improve from 0.12921\n",
      "\n",
      "Epoch 155: val_loss did not improve from 0.12921\n",
      "\n",
      "Epoch 156: val_loss improved from 0.12921 to 0.12904, saving model to ./code_03_model_result\\156-0.1290.hdf5\n",
      "\n",
      "Epoch 157: val_loss did not improve from 0.12904\n",
      "\n",
      "Epoch 158: val_loss did not improve from 0.12904\n",
      "\n",
      "Epoch 159: val_loss did not improve from 0.12904\n",
      "\n",
      "Epoch 160: val_loss improved from 0.12904 to 0.12715, saving model to ./code_03_model_result\\160-0.1272.hdf5\n",
      "\n",
      "Epoch 161: val_loss did not improve from 0.12715\n",
      "\n",
      "Epoch 162: val_loss did not improve from 0.12715\n",
      "\n",
      "Epoch 163: val_loss did not improve from 0.12715\n",
      "\n",
      "Epoch 164: val_loss did not improve from 0.12715\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.12715\n",
      "\n",
      "Epoch 166: val_loss improved from 0.12715 to 0.12537, saving model to ./code_03_model_result\\166-0.1254.hdf5\n",
      "\n",
      "Epoch 167: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 168: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 169: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 170: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 171: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 172: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 173: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 174: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 175: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 176: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 177: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 178: val_loss did not improve from 0.12537\n",
      "\n",
      "Epoch 179: val_loss improved from 0.12537 to 0.12412, saving model to ./code_03_model_result\\179-0.1241.hdf5\n",
      "\n",
      "Epoch 180: val_loss improved from 0.12412 to 0.12306, saving model to ./code_03_model_result\\180-0.1231.hdf5\n",
      "\n",
      "Epoch 181: val_loss did not improve from 0.12306\n",
      "\n",
      "Epoch 182: val_loss did not improve from 0.12306\n",
      "\n",
      "Epoch 183: val_loss improved from 0.12306 to 0.12211, saving model to ./code_03_model_result\\183-0.1221.hdf5\n",
      "\n",
      "Epoch 184: val_loss improved from 0.12211 to 0.12156, saving model to ./code_03_model_result\\184-0.1216.hdf5\n",
      "\n",
      "Epoch 185: val_loss did not improve from 0.12156\n",
      "\n",
      "Epoch 186: val_loss did not improve from 0.12156\n",
      "\n",
      "Epoch 187: val_loss improved from 0.12156 to 0.12083, saving model to ./code_03_model_result\\187-0.1208.hdf5\n",
      "\n",
      "Epoch 188: val_loss did not improve from 0.12083\n",
      "\n",
      "Epoch 189: val_loss did not improve from 0.12083\n",
      "\n",
      "Epoch 190: val_loss did not improve from 0.12083\n",
      "\n",
      "Epoch 191: val_loss improved from 0.12083 to 0.12003, saving model to ./code_03_model_result\\191-0.1200.hdf5\n",
      "\n",
      "Epoch 192: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 193: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 194: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 195: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 196: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 197: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 198: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 199: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 200: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 201: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 203: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 204: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 205: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 206: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 207: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 208: val_loss did not improve from 0.12003\n",
      "\n",
      "Epoch 209: val_loss improved from 0.12003 to 0.11904, saving model to ./code_03_model_result\\209-0.1190.hdf5\n",
      "\n",
      "Epoch 210: val_loss did not improve from 0.11904\n",
      "\n",
      "Epoch 211: val_loss did not improve from 0.11904\n",
      "\n",
      "Epoch 212: val_loss did not improve from 0.11904\n",
      "\n",
      "Epoch 213: val_loss improved from 0.11904 to 0.11714, saving model to ./code_03_model_result\\213-0.1171.hdf5\n",
      "\n",
      "Epoch 214: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 215: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 216: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 217: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 218: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 219: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 220: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 221: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 222: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 223: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 224: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 225: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 226: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 227: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 228: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 229: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 230: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 231: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 232: val_loss did not improve from 0.11714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 233: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 234: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.11714\n",
      "\n",
      "Epoch 236: val_loss improved from 0.11714 to 0.11612, saving model to ./code_03_model_result\\236-0.1161.hdf5\n",
      "\n",
      "Epoch 237: val_loss did not improve from 0.11612\n",
      "\n",
      "Epoch 238: val_loss did not improve from 0.11612\n",
      "\n",
      "Epoch 239: val_loss did not improve from 0.11612\n",
      "\n",
      "Epoch 240: val_loss did not improve from 0.11612\n",
      "\n",
      "Epoch 241: val_loss did not improve from 0.11612\n",
      "\n",
      "Epoch 242: val_loss did not improve from 0.11612\n",
      "\n",
      "Epoch 243: val_loss improved from 0.11612 to 0.11382, saving model to ./code_03_model_result\\243-0.1138.hdf5\n",
      "\n",
      "Epoch 244: val_loss improved from 0.11382 to 0.11283, saving model to ./code_03_model_result\\244-0.1128.hdf5\n",
      "\n",
      "Epoch 245: val_loss did not improve from 0.11283\n",
      "\n",
      "Epoch 246: val_loss did not improve from 0.11283\n",
      "\n",
      "Epoch 247: val_loss improved from 0.11283 to 0.11267, saving model to ./code_03_model_result\\247-0.1127.hdf5\n",
      "\n",
      "Epoch 248: val_loss did not improve from 0.11267\n",
      "\n",
      "Epoch 249: val_loss did not improve from 0.11267\n",
      "\n",
      "Epoch 250: val_loss did not improve from 0.11267\n",
      "\n",
      "Epoch 251: val_loss did not improve from 0.11267\n",
      "\n",
      "Epoch 252: val_loss did not improve from 0.11267\n",
      "\n",
      "Epoch 253: val_loss did not improve from 0.11267\n",
      "\n",
      "Epoch 254: val_loss improved from 0.11267 to 0.11104, saving model to ./code_03_model_result\\254-0.1110.hdf5\n",
      "\n",
      "Epoch 255: val_loss did not improve from 0.11104\n",
      "\n",
      "Epoch 256: val_loss did not improve from 0.11104\n",
      "\n",
      "Epoch 257: val_loss did not improve from 0.11104\n",
      "\n",
      "Epoch 258: val_loss improved from 0.11104 to 0.10956, saving model to ./code_03_model_result\\258-0.1096.hdf5\n",
      "\n",
      "Epoch 259: val_loss did not improve from 0.10956\n",
      "\n",
      "Epoch 260: val_loss did not improve from 0.10956\n",
      "\n",
      "Epoch 261: val_loss improved from 0.10956 to 0.10828, saving model to ./code_03_model_result\\261-0.1083.hdf5\n",
      "\n",
      "Epoch 262: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 263: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 264: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 265: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 266: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 267: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 268: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 269: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 270: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 271: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 272: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 273: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 274: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 275: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 276: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 277: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 278: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 279: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 280: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 281: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 282: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 283: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 284: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 285: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 286: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 287: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 288: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 289: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 290: val_loss did not improve from 0.10828\n",
      "\n",
      "Epoch 291: val_loss improved from 0.10828 to 0.10706, saving model to ./code_03_model_result\\291-0.1071.hdf5\n",
      "\n",
      "Epoch 292: val_loss did not improve from 0.10706\n",
      "\n",
      "Epoch 293: val_loss did not improve from 0.10706\n",
      "\n",
      "Epoch 294: val_loss did not improve from 0.10706\n",
      "\n",
      "Epoch 295: val_loss did not improve from 0.10706\n",
      "\n",
      "Epoch 296: val_loss improved from 0.10706 to 0.10591, saving model to ./code_03_model_result\\296-0.1059.hdf5\n",
      "\n",
      "Epoch 297: val_loss did not improve from 0.10591\n",
      "\n",
      "Epoch 298: val_loss did not improve from 0.10591\n",
      "\n",
      "Epoch 299: val_loss did not improve from 0.10591\n",
      "\n",
      "Epoch 300: val_loss improved from 0.10591 to 0.10422, saving model to ./code_03_model_result\\300-0.1042.hdf5\n",
      "\n",
      "Epoch 301: val_loss did not improve from 0.10422\n",
      "\n",
      "Epoch 302: val_loss did not improve from 0.10422\n",
      "\n",
      "Epoch 303: val_loss did not improve from 0.10422\n",
      "\n",
      "Epoch 304: val_loss did not improve from 0.10422\n",
      "\n",
      "Epoch 305: val_loss did not improve from 0.10422\n",
      "\n",
      "Epoch 306: val_loss improved from 0.10422 to 0.10386, saving model to ./code_03_model_result\\306-0.1039.hdf5\n",
      "\n",
      "Epoch 307: val_loss did not improve from 0.10386\n",
      "\n",
      "Epoch 308: val_loss did not improve from 0.10386\n",
      "\n",
      "Epoch 309: val_loss did not improve from 0.10386\n",
      "\n",
      "Epoch 310: val_loss did not improve from 0.10386\n",
      "\n",
      "Epoch 311: val_loss did not improve from 0.10386\n",
      "\n",
      "Epoch 312: val_loss did not improve from 0.10386\n",
      "\n",
      "Epoch 313: val_loss did not improve from 0.10386\n",
      "\n",
      "Epoch 314: val_loss did not improve from 0.10386\n",
      "\n",
      "Epoch 315: val_loss did not improve from 0.10386\n",
      "\n",
      "Epoch 316: val_loss improved from 0.10386 to 0.10307, saving model to ./code_03_model_result\\316-0.1031.hdf5\n",
      "\n",
      "Epoch 317: val_loss improved from 0.10307 to 0.10195, saving model to ./code_03_model_result\\317-0.1019.hdf5\n",
      "\n",
      "Epoch 318: val_loss did not improve from 0.10195\n",
      "\n",
      "Epoch 319: val_loss did not improve from 0.10195\n",
      "\n",
      "Epoch 320: val_loss did not improve from 0.10195\n",
      "\n",
      "Epoch 321: val_loss did not improve from 0.10195\n",
      "\n",
      "Epoch 322: val_loss did not improve from 0.10195\n",
      "\n",
      "Epoch 323: val_loss did not improve from 0.10195\n",
      "\n",
      "Epoch 324: val_loss did not improve from 0.10195\n",
      "\n",
      "Epoch 325: val_loss did not improve from 0.10195\n",
      "\n",
      "Epoch 326: val_loss did not improve from 0.10195\n",
      "\n",
      "Epoch 327: val_loss improved from 0.10195 to 0.10158, saving model to ./code_03_model_result\\327-0.1016.hdf5\n",
      "\n",
      "Epoch 328: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 329: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 330: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 331: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 332: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 333: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 334: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 335: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 336: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 337: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 338: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 339: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 340: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 341: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 342: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 343: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 344: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 345: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 346: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 347: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 348: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 349: val_loss did not improve from 0.10158\n",
      "\n",
      "Epoch 350: val_loss improved from 0.10158 to 0.09972, saving model to ./code_03_model_result\\350-0.0997.hdf5\n",
      "\n",
      "Epoch 351: val_loss improved from 0.09972 to 0.09949, saving model to ./code_03_model_result\\351-0.0995.hdf5\n",
      "\n",
      "Epoch 352: val_loss did not improve from 0.09949\n",
      "\n",
      "Epoch 353: val_loss did not improve from 0.09949\n",
      "\n",
      "Epoch 354: val_loss improved from 0.09949 to 0.09927, saving model to ./code_03_model_result\\354-0.0993.hdf5\n",
      "\n",
      "Epoch 355: val_loss did not improve from 0.09927\n",
      "\n",
      "Epoch 356: val_loss did not improve from 0.09927\n",
      "\n",
      "Epoch 357: val_loss improved from 0.09927 to 0.09913, saving model to ./code_03_model_result\\357-0.0991.hdf5\n",
      "\n",
      "Epoch 358: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 359: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 360: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 361: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 362: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 363: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 364: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 365: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 366: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 367: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 368: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 369: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 370: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 371: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 372: val_loss did not improve from 0.09913\n",
      "\n",
      "Epoch 373: val_loss improved from 0.09913 to 0.09656, saving model to ./code_03_model_result\\373-0.0966.hdf5\n",
      "\n",
      "Epoch 374: val_loss did not improve from 0.09656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 375: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 376: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 377: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 378: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 379: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 380: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 381: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 382: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 383: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 384: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 385: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 386: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 387: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 388: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 389: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 390: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 391: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 392: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 393: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 394: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 395: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 396: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 397: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 398: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 399: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 400: val_loss did not improve from 0.09656\n",
      "\n",
      "Epoch 401: val_loss improved from 0.09656 to 0.09650, saving model to ./code_03_model_result\\401-0.0965.hdf5\n",
      "\n",
      "Epoch 402: val_loss did not improve from 0.09650\n",
      "\n",
      "Epoch 403: val_loss did not improve from 0.09650\n",
      "\n",
      "Epoch 404: val_loss did not improve from 0.09650\n",
      "\n",
      "Epoch 405: val_loss did not improve from 0.09650\n",
      "\n",
      "Epoch 406: val_loss did not improve from 0.09650\n",
      "\n",
      "Epoch 407: val_loss did not improve from 0.09650\n",
      "\n",
      "Epoch 408: val_loss improved from 0.09650 to 0.09579, saving model to ./code_03_model_result\\408-0.0958.hdf5\n",
      "\n",
      "Epoch 409: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 410: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 411: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 412: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 413: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 414: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 415: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 416: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 417: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 418: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 419: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 420: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 421: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 422: val_loss did not improve from 0.09579\n",
      "\n",
      "Epoch 423: val_loss improved from 0.09579 to 0.09555, saving model to ./code_03_model_result\\423-0.0955.hdf5\n",
      "\n",
      "Epoch 424: val_loss did not improve from 0.09555\n",
      "\n",
      "Epoch 425: val_loss did not improve from 0.09555\n",
      "\n",
      "Epoch 426: val_loss did not improve from 0.09555\n",
      "\n",
      "Epoch 427: val_loss did not improve from 0.09555\n",
      "\n",
      "Epoch 428: val_loss did not improve from 0.09555\n",
      "\n",
      "Epoch 429: val_loss improved from 0.09555 to 0.09527, saving model to ./code_03_model_result\\429-0.0953.hdf5\n",
      "\n",
      "Epoch 430: val_loss improved from 0.09527 to 0.09469, saving model to ./code_03_model_result\\430-0.0947.hdf5\n",
      "\n",
      "Epoch 431: val_loss did not improve from 0.09469\n",
      "\n",
      "Epoch 432: val_loss did not improve from 0.09469\n",
      "\n",
      "Epoch 433: val_loss did not improve from 0.09469\n",
      "\n",
      "Epoch 434: val_loss did not improve from 0.09469\n",
      "\n",
      "Epoch 435: val_loss did not improve from 0.09469\n",
      "\n",
      "Epoch 436: val_loss did not improve from 0.09469\n",
      "\n",
      "Epoch 437: val_loss did not improve from 0.09469\n",
      "\n",
      "Epoch 438: val_loss improved from 0.09469 to 0.09467, saving model to ./code_03_model_result\\438-0.0947.hdf5\n",
      "\n",
      "Epoch 439: val_loss did not improve from 0.09467\n",
      "\n",
      "Epoch 440: val_loss did not improve from 0.09467\n",
      "\n",
      "Epoch 441: val_loss improved from 0.09467 to 0.09318, saving model to ./code_03_model_result\\441-0.0932.hdf5\n",
      "\n",
      "Epoch 442: val_loss did not improve from 0.09318\n",
      "\n",
      "Epoch 443: val_loss did not improve from 0.09318\n",
      "\n",
      "Epoch 444: val_loss did not improve from 0.09318\n",
      "\n",
      "Epoch 445: val_loss did not improve from 0.09318\n",
      "\n",
      "Epoch 446: val_loss did not improve from 0.09318\n",
      "\n",
      "Epoch 447: val_loss did not improve from 0.09318\n",
      "\n",
      "Epoch 448: val_loss did not improve from 0.09318\n",
      "\n",
      "Epoch 449: val_loss improved from 0.09318 to 0.09284, saving model to ./code_03_model_result\\449-0.0928.hdf5\n",
      "\n",
      "Epoch 450: val_loss did not improve from 0.09284\n",
      "\n",
      "Epoch 451: val_loss did not improve from 0.09284\n",
      "\n",
      "Epoch 452: val_loss did not improve from 0.09284\n",
      "\n",
      "Epoch 453: val_loss improved from 0.09284 to 0.09181, saving model to ./code_03_model_result\\453-0.0918.hdf5\n",
      "\n",
      "Epoch 454: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 455: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 456: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 457: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 458: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 459: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 460: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 461: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 462: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 463: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 464: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 465: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 466: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 467: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 468: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 469: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 470: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 471: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 472: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 473: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 474: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 475: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 476: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 477: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 478: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 479: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 480: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 481: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 482: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 483: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 484: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 485: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 486: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 487: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 488: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 489: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 490: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 491: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 492: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 493: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 494: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 495: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 496: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 497: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 498: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 499: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 500: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 501: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 502: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 503: val_loss did not improve from 0.09181\n",
      "\n",
      "Epoch 504: val_loss improved from 0.09181 to 0.09129, saving model to ./code_03_model_result\\504-0.0913.hdf5\n",
      "\n",
      "Epoch 505: val_loss did not improve from 0.09129\n",
      "\n",
      "Epoch 506: val_loss did not improve from 0.09129\n",
      "\n",
      "Epoch 507: val_loss improved from 0.09129 to 0.09103, saving model to ./code_03_model_result\\507-0.0910.hdf5\n",
      "\n",
      "Epoch 508: val_loss did not improve from 0.09103\n",
      "\n",
      "Epoch 509: val_loss did not improve from 0.09103\n",
      "\n",
      "Epoch 510: val_loss did not improve from 0.09103\n",
      "\n",
      "Epoch 511: val_loss did not improve from 0.09103\n",
      "\n",
      "Epoch 512: val_loss did not improve from 0.09103\n",
      "\n",
      "Epoch 513: val_loss did not improve from 0.09103\n",
      "\n",
      "Epoch 514: val_loss improved from 0.09103 to 0.09097, saving model to ./code_03_model_result\\514-0.0910.hdf5\n",
      "\n",
      "Epoch 515: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 516: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 517: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 518: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 519: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 520: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 521: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 522: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 523: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 524: val_loss did not improve from 0.09097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 525: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 526: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 527: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 528: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 529: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 530: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 531: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 532: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 533: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 534: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 535: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 536: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 537: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 538: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 539: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 540: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 541: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 542: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 543: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 544: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 545: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 546: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 547: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 548: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 549: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 550: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 551: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 552: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 553: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 554: val_loss did not improve from 0.09097\n",
      "\n",
      "Epoch 555: val_loss improved from 0.09097 to 0.09013, saving model to ./code_03_model_result\\555-0.0901.hdf5\n",
      "\n",
      "Epoch 556: val_loss did not improve from 0.09013\n",
      "\n",
      "Epoch 557: val_loss did not improve from 0.09013\n",
      "\n",
      "Epoch 558: val_loss improved from 0.09013 to 0.08986, saving model to ./code_03_model_result\\558-0.0899.hdf5\n",
      "\n",
      "Epoch 559: val_loss did not improve from 0.08986\n",
      "\n",
      "Epoch 560: val_loss did not improve from 0.08986\n",
      "\n",
      "Epoch 561: val_loss improved from 0.08986 to 0.08893, saving model to ./code_03_model_result\\561-0.0889.hdf5\n",
      "\n",
      "Epoch 562: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 563: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 564: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 565: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 566: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 567: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 568: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 569: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 570: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 571: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 572: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 573: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 574: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 575: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 576: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 577: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 578: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 579: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 580: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 581: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 582: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 583: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 584: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 585: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 586: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 587: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 588: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 589: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 590: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 591: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 592: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 593: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 594: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 595: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 596: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 597: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 598: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 599: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 600: val_loss did not improve from 0.08893\n",
      "\n",
      "Epoch 601: val_loss improved from 0.08893 to 0.08787, saving model to ./code_03_model_result\\601-0.0879.hdf5\n",
      "\n",
      "Epoch 602: val_loss did not improve from 0.08787\n",
      "\n",
      "Epoch 603: val_loss did not improve from 0.08787\n",
      "\n",
      "Epoch 604: val_loss did not improve from 0.08787\n",
      "\n",
      "Epoch 605: val_loss did not improve from 0.08787\n",
      "\n",
      "Epoch 606: val_loss did not improve from 0.08787\n",
      "\n",
      "Epoch 607: val_loss did not improve from 0.08787\n",
      "\n",
      "Epoch 608: val_loss did not improve from 0.08787\n",
      "\n",
      "Epoch 609: val_loss improved from 0.08787 to 0.08772, saving model to ./code_03_model_result\\609-0.0877.hdf5\n",
      "\n",
      "Epoch 610: val_loss did not improve from 0.08772\n",
      "\n",
      "Epoch 611: val_loss did not improve from 0.08772\n",
      "\n",
      "Epoch 612: val_loss improved from 0.08772 to 0.08719, saving model to ./code_03_model_result\\612-0.0872.hdf5\n",
      "\n",
      "Epoch 613: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 614: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 615: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 616: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 617: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 618: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 619: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 620: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 621: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 622: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 623: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 624: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 625: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 626: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 627: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 628: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 629: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 630: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 631: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 632: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 633: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 634: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 635: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 636: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 637: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 638: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 639: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 640: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 641: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 642: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 643: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 644: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 645: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 646: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 647: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 648: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 649: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 650: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 651: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 652: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 653: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 654: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 655: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 656: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 657: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 658: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 659: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 660: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 661: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 662: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 663: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 664: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 665: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 666: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 667: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 668: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 669: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 670: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 671: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 672: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 673: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 674: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 675: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 676: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 677: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 678: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 679: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 680: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 681: val_loss did not improve from 0.08719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 682: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 683: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 684: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 685: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 686: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 687: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 688: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 689: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 690: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 691: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 692: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 693: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 694: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 695: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 696: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 697: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 698: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 699: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 700: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 701: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 702: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 703: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 704: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 705: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 706: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 707: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 708: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 709: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 710: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 711: val_loss did not improve from 0.08719\n",
      "\n",
      "Epoch 712: val_loss did not improve from 0.08719\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df_pre = pd.read_csv('../dataset/wine.csv', header=None)\n",
    "df = df_pre.sample(frac=0.15)\n",
    "dataset = df.values\n",
    "X = dataset[:, 0:12]\n",
    "Y = dataset[:, 12]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "MODEL_DIR = './code_03_model_result/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = \"./code_03_model_result/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)\n",
    "\n",
    "history = model.fit(X, Y, validation_split=0.2, epochs=3500, batch_size=500, \n",
    "          verbose=0, callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27808bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "y_acc = history.history['accuracy']\n",
    "\n",
    "x_len = numpy.arange(len(y_acc))\n",
    "plt.ylim(0, 1.1, 0.2)\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3, label='val_loss')\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"cornflowerblue\", markersize=3, label='accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
